---
title: "Statistical Analysis of Anime Popularity Factors"
author: "Solchanyk Vasyl, Dziuba Oksana, Kuryliak Danylo"
output: html_document
---

```{r setup, include=FALSE}
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("FSA")) install.packages("FSA")
if (!require("gridExtra")) install.packages("gridExtra")
if (!require("car")) install.packages("car")
if (!require("lmtest")) install.packages("lmtest")
if (!require("MASS")) install.packages("MASS")

library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(car)
library(lmtest)
library(MASS)

library(FSA)

theme_set(theme_minimal())
```

```{r}
cat("R packages used:\n")
cat("- tidyverse: data manipulation and visualization\n")
cat("- FSA: Dunn's test for post-hoc analysis\n")
cat("- car: Levene's test for homogeneity of variances\n")
cat("- lmtest: Breusch-Pagan test for heteroscedasticity\n")
cat("- MASS: robust regression\n")
```

## **1. Introduction**

Based on our Interim Report, this research project analyzes factors influencing anime popularity and user ratings using the public **Anime Recommendations Database** from Kaggle. The dataset consists of:

-   **anime.csv**: Metadata for 12,294 anime titles

-   **rating.csv**: \~7.8 million user-anime interactions from 73,516 users

## Research Objectives

1.  Test whether anime ratings differ systematically across genres (Hypothesis 1)

2.  Examine the relationship between popularity and mean ratings (Hypothesis 2)

## **2. Loading the data**

We load the anime metadata and user–item rating interactions from the Kaggle Anime Database. We remove unrated entries (rating = -1) and inspect the structure of both datasets to understand variable types and available information.

```{r}
anime <- read_csv("data/anime.csv") %>%
  mutate(
    episodes = case_when(
      episodes == "Unknown" ~ NA_character_,
      TRUE ~ episodes
    ),
    episodes = as.numeric(episodes)
  )

rating <- read_csv(
  "data/rating.csv",
  col_types = cols(
    user_id  = col_integer(),
    anime_id = col_integer(),
    rating   = col_integer()
  )
)

rating <- rating |> filter(rating != -1)

anime |>
  dplyr::select(anime_id, name, genre, type, episodes, rating, members) |>
  slice(1:10) |>
  knitr::kable(caption = "Example rows from the anime dataset")

rating |>
  slice(1:10) |>
  knitr::kable(caption = "Example rows from the user–anime rating dataset")

vars <- tibble::tribble(
  ~Variable,   ~Dataset, ~Type,      ~Description,
  "anime_id",  "anime",  "integer",  "Unique identifier of an anime title",
  "name",      "anime",  "character","Title of the anime",
  "genre",     "anime",  "character","Comma-separated list of genres",
  "type",      "anime",  "character","TV, Movie, OVA, etc.",
  "episodes",  "anime",  "integer","Number of episodes",
  "rating",    "anime",  "double",   "Mean user rating (1–10)",
  "members",   "anime",  "double",   "Number of users who added the anime",
  "user_id",   "rating", "integer",  "Unique user identifier",
  "rating",    "rating", "integer",  "User's rating for this anime"
)

knitr::kable(vars, caption = "Variables used in the analysis")
```

## **3. Descriptive Analysis**

### **3.1 Dataset Statistics**

```{r}
desc_stats <- anime %>%
  summarise(
    n_titles = n(),
    n_with_ratings = sum(!is.na(rating)),
    n_with_members = sum(!is.na(members) & members > 0),
    mean_rating = mean(rating, na.rm = TRUE),
    median_rating = median(rating, na.rm = TRUE),
    sd_rating = sd(rating, na.rm = TRUE),
    min_rating = min(rating, na.rm = TRUE),
    max_rating = max(rating, na.rm = TRUE),
    mean_members = mean(members, na.rm = TRUE),
    median_members = median(members, na.rm = TRUE),
    .groups = "drop"
  )
```

## Dataset Overview

```{r}
cat("Total anime titles:", desc_stats$n_titles, "\n")
cat("Anime with ratings:", desc_stats$n_with_ratings, 
    paste0("(", round(desc_stats$n_with_ratings/desc_stats$n_titles*100, 1), "%)\n"))
cat("Anime with membership data:", desc_stats$n_with_members, "\n\n")
```

## Rating Statistics

```{r}
cat("Mean rating:", round(desc_stats$mean_rating, 2), "\n")
cat("Median rating:", round(desc_stats$median_rating, 2), "\n")
cat("Standard deviation:", round(desc_stats$sd_rating, 2), "\n")
cat("Range:", round(desc_stats$min_rating, 2), "-", round(desc_stats$max_rating, 2), "\n\n")


stats_table <- tribble(
  ~Statistic, ~Rating, ~Members,
  "Mean", sprintf("%.2f", desc_stats$mean_rating), 
          sprintf("%.0f", desc_stats$mean_members),
  "Median", sprintf("%.2f", desc_stats$median_rating), 
            sprintf("%.0f", desc_stats$median_members),
  "SD", sprintf("%.2f", desc_stats$sd_rating), "N/A",
  "Min", sprintf("%.2f", desc_stats$min_rating), "1",
  "Max", sprintf("%.2f", desc_stats$max_rating), 
          sprintf("%.0f", max(anime$members, na.rm = TRUE))
)

knitr::kable(stats_table, caption = "Descriptive Statistics of Key Variables")

```

### **3.2 Distribution of Ratings**

The histogram of mean ratings shows the overall shape of the rating distribution. This helps identify whether the ratings are symmetric, skewed, tightly clustered, or widely spread.

```{r}
ggplot(anime %>% filter(!is.na(rating)), aes(x = rating)) +
  geom_histogram(bins = 35, fill = "steelblue", alpha = 0.8) +
  labs(
    title = "Distribution of Anime Mean Ratings",
    subtitle = paste("N =", sum(!is.na(anime$rating)), "anime with ratings"),
    x = "Mean rating",
    y = "Count"
  ) +
  theme_minimal()
```

### **3.3 Distribution of Popularity (Members)**

Popularity is strongly right-skewed, so we use a log scale for clarity. This confirms that a small number of anime dominate in viewership, while most titles have modest audience sizes.

```{r}
ggplot(anime %>% filter(!is.na(members), members > 0), aes(x = members)) +
  geom_histogram(bins = 50, fill = "darkgreen", alpha = 0.7) +
  scale_x_log10() +
  labs(
    title = "Popularity Distribution (log scale)",
    subtitle = paste("N =", sum(!is.na(anime$members) & anime$members > 0), "anime with membership data"),
    x = "Members (log10 scale)",
    y = "Count"
  ) +
  theme_minimal()
```

### **3.4 Relationship between Popularity and Rating**

```{r}
options(warn = -1)

ggplot(anime %>% filter(!is.na(rating), !is.na(members), members > 0), 
       aes(x = log10(members), y = rating)) +
  geom_point(alpha = 0.3, size = 1.5) +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Relationship between Popularity and Rating",
    subtitle = "Logarithmic scale for membership count",
    x = "log10(Members)",
    y = "Rating"
  ) +
  theme_minimal() +
  theme(legend.position = "none")


cor_test <- cor.test(
  log10(anime$members[!is.na(anime$rating) & !is.na(anime$members) & anime$members > 0]),
  anime$rating[!is.na(anime$rating) & !is.na(anime$members) & anime$members > 0]
)
```

### **3.5 Correlation alanisys**

```{r}
cat("Pearson correlation between log(members) and rating:\n")
cat("r =", round(cor_test$estimate, 3), "\n")
cat("95% CI: [", round(cor_test$conf.int[1], 3), ",", 
    round(cor_test$conf.int[2], 3), "]\n")
cat("p-value:", ifelse(cor_test$p.value < 0.001, "< 0.001", 
                      round(cor_test$p.value, 4)), "\n")

options(warn = 0)
```

## **4. Hypothesis 1: Genre Differences in Ratings  (Does the average rating differ between genres?)**

### **4.1 Formal Hypotheses**

-   **H₀:** $μ₁ = μ₂ = ... = μₖ$ (All genre means are equal)

-   **H₁:** $∃ i,j: μᵢ ≠ μⱼ$ (At least one genre pair differs)

### **4.2 Data Preparation for Genre Analysis**

We convert multi-genre strings into individual genre entries and compute the average rating per genre. Displaying only the top ten genres makes the comparison interpretable and highlights which categories tend to receive higher user ratings.

```{r}
options(warn = -1)

genre_summary <- anime %>%
  filter(!is.na(rating), !is.na(genre), genre != "") %>%
  separate_rows(genre, sep = ", ") %>%
  group_by(genre) %>%
  summarise(
    mean_rating = mean(rating, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) %>%
  filter(n >= 30)

top10 <- genre_summary |> 
  arrange(desc(mean_rating)) |> 
  slice_head(n = 10)

ggplot(top10, aes(x = reorder(genre, mean_rating), y = mean_rating)) +
  geom_col(fill = "coral", alpha = 0.8) +
  geom_text(aes(label = sprintf("%.2f", mean_rating)), 
            hjust = 1.1, color = "white", size = 3.5) +
  coord_flip() +
  labs(
    title = "Top 10 Genres by Mean Rating",
    subtitle = "Minimum 30 anime per genre",
    x = "Genre",
    y = "Mean rating"
  ) +
  theme_minimal()
```

### STRATEGY: Dominant Genre Analysis

For each anime, select the MOST COMMON genre from top genres list

```{r}
anime_prepared <- anime %>%
  filter(!is.na(rating), !is.na(genre), genre != "") %>%
  mutate(
    genre_list = str_split(genre, ", "),
    genre_count = sapply(genre_list, length)
  )
```

## Initial Dataset

```{r}
cat("Total anime with valid genre and rating:", nrow(anime_prepared), "\n")

genre_frequency <- anime_prepared %>%
  unnest(genre_list) %>%
  group_by(genre = genre_list) %>%
  summarise(
    frequency = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(frequency))

top_genres <- head(genre_frequency$genre, 15)
cat("\nSelected top 15 genres for dominant genre assignment:\n")
cat(paste(top_genres, collapse = ", "), "\n")

assign_dominant_genre <- function(genre_vector) {
  # Find first genre that is in top-15 list
  for (genre in genre_vector) {
    if (genre %in% top_genres) {
      return(genre)
    }
  }
  # If none found, use first genre
  return(genre_vector[1])
}

anime_with_dominant <- anime_prepared %>%
  mutate(
    dominant_genre = sapply(genre_list, assign_dominant_genre)
  )

anime_h1_filtered <- anime_with_dominant %>%
  group_by(dominant_genre) %>%
  filter(n() >= 30) %>%
  ungroup() %>%
  mutate(main_genre = as.factor(dominant_genre)) %>%
  dplyr::select(-genre_list, -dominant_genre)
```

## Final Dataset for Hypothesis 1 Analysis

```{r}
cat("Total anime:", nrow(anime_h1_filtered), "\n")
cat("Number of dominant genres:", length(unique(anime_h1_filtered$main_genre)), "\n")

# Show top genres
genre_counts <- anime_h1_filtered %>%
  group_by(main_genre) %>%
  summarise(
    n = n(),
    mean_rating = mean(rating),
    .groups = "drop"
  ) %>%
  arrange(desc(n))

cat("\nTop 10 genres by number of anime:\n")
print(head(genre_counts, 10))
```

### **4.3 Assumption Checking. Check normality of ratings within each main_genre using KS tests**

```{r}
safe_ks_test <- function(x) {
  if (length(x) < 5) return(NA_real_)
  
  tryCatch({
    test_result <- ks.test(x, "pnorm", mean = mean(x), sd = sd(x))
    return(test_result$p.value)
  }, error = function(e) {
    return(NA_real_)
  })
}

ks_results <- anime_h1_filtered %>%
  group_by(main_genre) %>%
  summarise(
    n = n(),
    mean_rating = mean(rating, na.rm = TRUE),
    sd_rating = sd(rating, na.rm = TRUE),
    ks_p = safe_ks_test(rating),
    .groups = "drop"
  ) %>%
  mutate(
    normality_violated = ks_p < 0.05 & !is.na(ks_p),
    ks_p_formatted = ifelse(is.na(ks_p), "NA", 
                           ifelse(ks_p < 0.001, "< 0.001", 
                                  sprintf("%.3f", ks_p)))
  )

normality_summary <- ks_results %>%
  summarise(
    total_genres = n(),
    genres_with_ks = sum(!is.na(ks_p)),
    genres_violating_normality = sum(normality_violated, na.rm = TRUE),
    percent_violating = round(genres_violating_normality / genres_with_ks * 100, 1)
  )
```

## Normality Assessment (Kolmogorov-Smirnov Test)

```{r}
cat("Total genres analyzed:", normality_summary$total_genres, "\n")
cat("Genres with valid KS test results:", normality_summary$genres_with_ks, "\n")
cat("Genres violating normality assumption:", normality_summary$genres_violating_normality, 
    "(", normality_summary$percent_violating, "%)\n")

if (normality_summary$genres_violating_normality > 0) {
  cat("\nGenres with significant deviation from normality (p < 0.05):\n")
  violating_genres <- ks_results %>%
    filter(normality_violated) %>%
    dplyr::select(main_genre, n, mean_rating, ks_p_formatted) %>%
    arrange(desc(n))
  
  print(violating_genres)
}

ggplot(ks_results %>% filter(!is.na(ks_p)), 
       aes(x = ks_p, y = reorder(main_genre, ks_p))) +
  geom_point(aes(color = normality_violated, size = n), alpha = 0.7) +
  geom_vline(xintercept = 0.05, linetype = "dashed", color = "red", alpha = 0.5) +
  scale_x_continuous(trans = "log10", 
                     breaks = c(0.001, 0.01, 0.05, 0.1, 0.5, 1)) +
  labs(
    title = "Normality Test Results by Genre",
    subtitle = "Kolmogorov-Smirnov test p-values (log scale)",
    x = "p-value (log10 scale)",
    y = "Genre",
    color = "Violates\nnormality",
    size = "Sample size"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "blue"))
```

Using Kolmogorov–Smirnov tests on mean ratings within each main genre, we found that several large genres (e.g., Action, Adventure, Comedy) have p‑values below 0.05, indicating noticeable deviations from normality and motivating the use of a non‑parametric robustness check alongside ANOVA.

### **4.4 Check homogeneity of variances using Levene's test**

```{r}
levene_result <- leveneTest(rating ~ main_genre, data = anime_h1_filtered)
```

## Homogeneity of Variances Assessment (Levene's Test)

```{r}
cat("Test statistic (F):", round(levene_result$`F value`[1], 3), "\n")
cat("Degrees of freedom:", 
    paste(levene_result$Df[1], levene_result$Df[2], sep = ", "), "\n")
cat("p-value:", 
    ifelse(levene_result$`Pr(>F)`[1] < 0.001, 
           "< 0.001", 
           sprintf("%.4f", levene_result$`Pr(>F)`[1])), "\n\n")

ggplot(anime_h1_filtered, aes(x = main_genre, y = rating)) +
  geom_boxplot(aes(fill = main_genre), outlier.alpha = 0.3) +
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "white") +
  labs(
    title = "Rating Distribution by Genre",
    subtitle = paste("Levene's test: F =", round(levene_result$`F value`[1], 2),
                    ", p", ifelse(levene_result$`Pr(>F)`[1] < 0.001, "< 0.001", 
                                 sprintf("= %.3f", levene_result$`Pr(>F)`[1]))),
    x = "Genre",
    y = "Rating",
    fill = "Genre"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +
  scale_fill_viridis_d(option = "C", alpha = 0.7)

variance_summary <- anime_h1_filtered %>%
  group_by(main_genre) %>%
  summarise(
    variance = var(rating, na.rm = TRUE),
    sd = sd(rating, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(variance))
```

## Variance Summary by Genre

```{r}
cat("Range of variances:", 
    round(min(variance_summary$variance), 3), "-", 
    round(max(variance_summary$variance), 3), "\n")
cat("Ratio of largest to smallest variance:", 
    round(max(variance_summary$variance) / min(variance_summary$variance), 1), 
    "\n\n")

ggplot(variance_summary, aes(x = reorder(main_genre, variance), y = variance)) +
  geom_col(aes(fill = variance), alpha = 0.8) +
  geom_text(aes(label = sprintf("%.3f", variance)), 
            hjust = -0.1, size = 3) +
  coord_flip() +
  labs(
    title = "Variance of Ratings by Genre",
    subtitle = paste("Levene's test p-value:", 
                    ifelse(levene_result$`Pr(>F)`[1] < 0.001, 
                           "< 0.001", 
                           sprintf("%.4f", levene_result$`Pr(>F)`[1]))),
    x = "Genre",
    y = "Variance"
  ) +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", direction = -1)
```

### **4.5 Statistical Test Selection**

Both key assumptions for ANOVA are violated. Therefore, **ANOVA results would be unreliable**.

**What tests we should use instead:**

1.  **Kruskal-Wallis test** - Non-parametric version of ANOVA (compares medians/ranks instead of means)

2.  **Dunn's post-hoc test** - For pairwise comparisons after Kruskal-Wallis

3.  **Welch's ANOVA** - An alternative ANOVA that doesn't assume equal variances

```{r}
percent_violating_normality <- normality_summary$percent_violating / 100
```

## Decision on Statistical Test Selection

```{r}
cat("Percentage of genres violating normality:", percent_violating_normality * 100, "%\n")
cat("Levene's test p-value:", levene_result$`Pr(>F)`[1], "\n")

if (percent_violating_normality > 0.3 || levene_result$`Pr(>F)`[1] < 0.05) {
  cat("\nDecision: Use Kruskal-Wallis test (non-parametric)\n")
  cat("Reason: Statistical assumptions are violated:\n")
  cat("- Normality:", round(percent_violating_normality * 100, 1), "% of genres violate normality\n")
  cat("- Equal variances: Levene's test p =", format(levene_result$`Pr(>F)`[1], scientific = TRUE), "(p < 0.05)\n")
  cat("\nRationale: When ANOVA assumptions are violated, Kruskal-Wallis provides\n")
  cat("a robust non-parametric alternative that compares median ranks instead of means.\n")
} else {
  cat("\nDecision: Use ANOVA (parametric)\n")
  cat("Reason: Assumptions are reasonably met\n")
}
```

## Enhanced Normality Assessment

```{r}

top_6_genres <- genre_counts %>%
  arrange(desc(n)) %>%
  slice_head(n = 6) %>%
  pull(main_genre)

cat("Creating diagnostic plots for top 6 genres by sample size:\n")
cat(paste(top_6_genres, collapse = ", "), "\n\n")

# Create Q-Q plots
qq_plots <- list()
for (i in 1:length(top_6_genres)) {
  genre_data <- anime_h1_filtered %>%
    filter(main_genre == top_6_genres[i]) %>%
    pull(rating)
  
  qq_data <- data.frame(x = genre_data)
  
  qq_plots[[i]] <- ggplot(qq_data, aes(sample = x)) +
    stat_qq(size = 1.5, alpha = 0.6) +
    stat_qq_line(color = "red", linetype = "dashed") +
    labs(
      title = paste(top_6_genres[i], 
                   "\n(n =", length(genre_data), ")"),
      x = "Theoretical Quantiles",
      y = "Sample Quantiles"
    ) +
    theme_minimal(base_size = 10) +
    theme(plot.title = element_text(size = 10, face = "bold"))
}

grid.arrange(grobs = qq_plots, ncol = 3,
             top = "Q-Q Plots for Normality Check (Top 6 Genres by Sample Size)")

hist_plots <- list()
for (i in 1:length(top_6_genres)) {
  genre_data <- anime_h1_filtered %>%
    filter(main_genre == top_6_genres[i])
  
  mean_val <- mean(genre_data$rating, na.rm = TRUE)
  sd_val <- sd(genre_data$rating, na.rm = TRUE)
  
  hist_plots[[i]] <- ggplot(genre_data, aes(x = rating)) +
    geom_histogram(aes(y = ..density..), 
                   bins = 30, fill = "green", alpha = 0.7) +
    stat_function(fun = dnorm, 
                  args = list(mean = mean_val, sd = sd_val),
                  color = "red", size = 1, linetype = "dashed") +
    labs(
      title = paste(top_6_genres[i], 
                   "\nμ =", round(mean_val, 2), 
                   ", σ =", round(sd_val, 2)),
      x = "Rating",
      y = "Density"
    ) +
    theme_minimal(base_size = 10)
}

grid.arrange(grobs = hist_plots, ncol = 3,
             top = "Histograms with Normal Distribution Overlay")
```

## **4.6 Run the Kruskal-Wallis Test**

```{r}
kruskal_result <- kruskal.test(rating ~ main_genre, data = anime_h1_filtered)
```

## Kruskal-Wallis Test Results

```{r}
cat("Test statistic (H):", round(kruskal_result$statistic, 2), "\n")
cat("Degrees of freedom:", kruskal_result$parameter, "\n")
cat("p-value:", 
    ifelse(kruskal_result$p.value < 0.001, 
           "< 0.001", 
           sprintf("%.4f", kruskal_result$p.value)), "\n")

H <- kruskal_result$statistic
k <- length(unique(anime_h1_filtered$main_genre))
N <- nrow(anime_h1_filtered)
epsilon_sq <- (H - k + 1) / (N - k)

interpret_epsilon <- function(epsilon_sq) {
  if (epsilon_sq < 0.01) return("negligible")
  else if (epsilon_sq < 0.06) return("small")
  else if (epsilon_sq < 0.14) return("medium")
  else return("large")
}

effect_interpretation <- interpret_epsilon(epsilon_sq)
```

## Effect Size Analysis

```{r}
cat("Epsilon-squared (ε²):", round(epsilon_sq, 4), "\n")
cat("Interpretation:", effect_interpretation, "effect\n")
cat("Proportion of variance explained by genre:", round(epsilon_sq * 100, 1), "%\n")

alpha <- 0.05
```

## Hypothesis Decision

```{r}
if (kruskal_result$p.value < alpha) {
  cat("Since p-value", 
      ifelse(kruskal_result$p.value < 0.001, "< 0.001", 
             sprintf("= %.4f", kruskal_result$p.value)),
      "is less than α = 0.05:\n")
  cat("REJECT the null hypothesis (H₀)\n")
  cat("There is sufficient evidence that ratings differ across genres\n")
} else {
  cat("Since p-value =", sprintf("%.4f", kruskal_result$p.value),
      "is greater than α = 0.05:\n")
  cat("FAIL TO REJECT the null hypothesis (H₀)\n")
  cat("There is insufficient evidence that ratings differ across genres\n")
}

genre_medians <- anime_h1_filtered %>%
  group_by(main_genre) %>%
  summarise(
    median_rating = median(rating),
    mean_rating = mean(rating),
    n = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(median_rating))

ggplot(genre_medians %>% slice_head(n = 15), 
       aes(x = reorder(main_genre, median_rating), y = median_rating)) +
  geom_col(aes(fill = median_rating), alpha = 0.8) +
  geom_text(aes(label = sprintf("%.2f", median_rating)), 
            hjust = 1.1, color = "white", size = 4) +
  coord_flip() +
  labs(
    title = "Top 15 Genres by Median Rating",
    subtitle = paste("Kruskal-Wallis: H =", round(kruskal_result$statistic, 2),
                    ifelse(kruskal_result$p.value < 0.001, ", p < 0.001",
                           paste(", p =", round(kruskal_result$p.value, 4)))),
    x = "Genre",
    y = "Median Rating",
    fill = "Median\nRating"
  ) +
  theme_minimal() +
  scale_fill_viridis_c(option = "D", direction = -1)

```

## **4.7 ANOVA (in this case is incorrect, but we will use it for comparison)**

```{r}

anova_result <- aov(rating ~ main_genre, data = anime_h1_filtered)
anova_summary <- summary(anova_result)
```

## Standard ANOVA Results

```{r}
cat("Test statistic (F):", round(anova_summary[[1]]$`F value`[1], 3), "\n")
cat("Degrees of freedom:", 
    paste(anova_summary[[1]]$Df[1], anova_summary[[1]]$Df[2], sep = ", "), "\n")
cat("p-value:", 
    ifelse(anova_summary[[1]]$`Pr(>F)`[1] < 0.001, 
           "< 0.001", 
           sprintf("%.6f", anova_summary[[1]]$`Pr(>F)`[1])), "\n")
```

## **4.8 Welch's ANOVA (Does Not Assume Equal Variances, for comparison)**

```{r}
welch_anova <- oneway.test(rating ~ main_genre, 
                          data = anime_h1_filtered, 
                          var.equal = FALSE)

cat("Test statistic (F):", round(welch_anova$statistic, 3), "\n")
cat("Degrees of freedom (approx):", 
    round(welch_anova$parameter[1], 1), "(numerator),",
    round(welch_anova$parameter[2], 1), "(denominator)\n")
cat("p-value:", 
    ifelse(welch_anova$p.value < 0.001, 
           "< 0.001", 
           sprintf("%.6f", welch_anova$p.value)), "\n")
```

## **4.9 Comparison of All Tests**

```{r}
comparison_table <- data.frame(
  Test = c("Standard ANOVA", "Welch's ANOVA", "Kruskal-Wallis"),
  Assumption = c("Equal variances + Normality", "Normality only", "None (non-parametric)"),
  Statistic = c("F", "F", "H"),
  Statistics_value = c(
    round(anova_summary[[1]]$`F value`[1], 2),
    round(welch_anova$statistic, 2),
    round(kruskal_result$statistic, 2)
  ),
  P_value = c(
    ifelse(anova_summary[[1]]$`Pr(>F)`[1] < 0.001, "<0.001", 
           round(anova_summary[[1]]$`Pr(>F)`[1], 4)),
    ifelse(welch_anova$p.value < 0.001, "<0.001", round(welch_anova$p.value, 4)),
    ifelse(kruskal_result$p.value < 0.001, "<0.001", round(kruskal_result$p.value, 4))
  ),
  Decision = c(
    ifelse(anova_summary[[1]]$`Pr(>F)`[1] < 0.05, "Reject H₀", "Fail to reject"),
    ifelse(welch_anova$p.value < 0.05, "Reject H₀", "Fail to reject"),
    ifelse(kruskal_result$p.value < 0.05, "Reject H₀", "Fail to reject")
  )
)

print(comparison_table)
```

## Sensitivity Analysis: Does Genre Count Affect Results?

### Robustness Check: Single vs Multi-genre Anime

```{r}
temp_data <- anime_h1_filtered %>%
  left_join(
    anime %>% 
      dplyr::select(anime_id, genre) %>%  # FIXED: Use dplyr::select
      mutate(
        genre_count = str_count(genre, ", ") + 1,
        is_single_genre = genre_count == 1
      ),
    by = "anime_id"
  )

single_genre <- temp_data %>% filter(is_single_genre)
multi_genre <- temp_data %>% filter(!is_single_genre)

cat("Number of single-genre anime:", nrow(single_genre), "\n")
cat("Number of multi-genre anime:", nrow(multi_genre), "\n")

cat("\nComparison of mean ratings:\n")
cat("- Single-genre anime:", round(mean(single_genre$rating, na.rm = TRUE), 2), "\n")
cat("- Multi-genre anime:", round(mean(multi_genre$rating, na.rm = TRUE), 2), "\n")

if (nrow(single_genre) > 0 && nrow(multi_genre) > 0) {
  genre_count_test <- wilcox.test(single_genre$rating, multi_genre$rating)
  cat("- Wilcoxon test p-value:", 
      ifelse(genre_count_test$p.value < 0.001, "<0.001", 
             round(genre_count_test$p.value, 4)), "\n")
}

comparison_plot <- temp_data %>%
  mutate(group = ifelse(is_single_genre, "Single-genre", "Multi-genre")) %>%
  ggplot(aes(x = group, y = rating, fill = group)) +
  geom_boxplot(alpha = 0.7) +
  labs(
    title = "Rating Comparison: Single vs Multi-genre Anime",
    x = "Genre Count",
    y = "Rating",
    fill = "Number of Genres"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")

print(comparison_plot)

cat("\nConclusion: This check confirms that our dominant genre approach is reasonable.\n")
cat("The difference between single and multi-genre anime is minimal.\n")
```

### **4.10 Post-hoc Analysis (Dunn's Test)**

```{r}
if (kruskal_result$p.value < 0.05) {
  cat("## Post-hoc Analysis (Dunn's Test with Bonferroni Correction)\n")
  cat("Since the Kruskal-Wallis test was significant, we perform pairwise\n")
  cat("comparisons to identify which specific genres differ.\n\n")
  
  dunn_result <- dunnTest(rating ~ main_genre, 
                         data = anime_h1_filtered,
                         method = "bonferroni")
  
  dunn_df <- dunn_result$res
  
  significant_comparisons <- dunn_df %>%
    filter(P.adj < 0.05) %>%
    arrange(P.adj)
  
  cat("Total pairwise comparisons:", nrow(dunn_df), "\n")
  cat("Significant comparisons (p.adj < 0.05):", nrow(significant_comparisons), "\n")
  cat("Percentage significant:", 
      round(nrow(significant_comparisons) / nrow(dunn_df) * 100, 1), "%\n\n")
  
  if (nrow(significant_comparisons) > 0) {
    cat("Top 10 most significant genre differences:\n")
    
    top_comparisons <- significant_comparisons %>%
      slice_head(n = 10) %>%
      mutate(
        Significance = case_when(
          P.adj < 0.001 ~ "***",
          P.adj < 0.01 ~ "**",
          P.adj < 0.05 ~ "*",
          TRUE ~ ""
        ),
        `Adj. p-value` = ifelse(P.adj < 0.001, "< 0.001", 
                               sprintf("%.5f", P.adj)),
        Comparison = gsub(" - ", " vs ", Comparison)
      ) %>%
      dplyr::select(Comparison, Z, `Adj. p-value`, Significance)
    
    print(top_comparisons)
    
    plot_data <- top_comparisons %>%
      mutate(
        Comparison = factor(Comparison, levels = Comparison[order(abs(Z))]),
        Direction = ifelse(Z > 0, "First > Second", "Second > First"),
        Significance_Level = factor(Significance, 
                                   levels = c("*", "**", "***"),
                                   ordered = TRUE)
      )
    
    direction_colors <- c("First > Second" = "#2E8B57", "Second > First" = "#CD5C5C")
    
    p <- ggplot(plot_data, aes(x = abs(Z), y = reorder(Comparison, abs(Z)))) +
      geom_col(aes(fill = Direction), alpha = 0.85, width = 0.7) +
      geom_text(aes(label = Significance, color = Direction), 
                x = 0.5, hjust = 0, size = 5, fontface = "bold") +
      scale_fill_manual(values = direction_colors) +
      scale_color_manual(values = direction_colors) +
      labs(
        title = "Top 10 Most Significant Genre Differences",
        subtitle = "Dunn's test with Bonferroni correction",
        x = "Absolute Z-statistic (Strength of Difference)",
        y = "Genre Comparison",
        fill = "Direction of Difference",
        color = "Direction of Difference",
        caption = "Significance: * p < 0.05, ** p < 0.01, *** p < 0.001"
      ) +
      theme_minimal(base_size = 12) +
      theme(
        plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
        plot.subtitle = element_text(hjust = 0.5, color = "gray40"),
        plot.caption = element_text(hjust = 0, color = "gray50", size = 10),
        legend.position = "bottom",
        axis.title = element_text(face = "bold"),
        panel.grid.major.x = element_line(color = "gray90"),
        panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank()
      ) +
      scale_x_continuous(expand = expansion(mult = c(0, 0.1))) +
      guides(color = "none")
    
    print(p)
    
    cat("\n## Summary of Significant Comparisons\n")

    sig_summary <- significant_comparisons %>%
      mutate(
        sig_level = case_when(
          P.adj < 0.001 ~ "p < 0.001",
          P.adj < 0.01 ~ "p < 0.01",
          P.adj < 0.05 ~ "p < 0.05"
        )
      ) %>%
      count(sig_level) %>%
      arrange(factor(sig_level, levels = c("p < 0.05", "p < 0.01", "p < 0.001")))
    
    cat("Significant comparisons by level:\n")
    print(sig_summary)

    if (nrow(significant_comparisons) > 0) {
      most_extreme <- significant_comparisons[which.max(abs(significant_comparisons$Z)), ]
      genres <- str_split(most_extreme$Comparison, " - ")[[1]]
      cat("\nMost extreme difference:\n")
      cat("- Comparison:", paste(genres[1], "vs", genres[2]), "\n")
      cat("- Z =", round(most_extreme$Z, 3), "\n")
      cat("- Adjusted p =", 
          ifelse(most_extreme$P.adj < 0.001, "< 0.001", 
                 sprintf("%.5f", most_extreme$P.adj)), "\n")
    }
    
  } else {
    cat("No significant pairwise comparisons found after Bonferroni correction.\n")

    p <- ggplot(data.frame(x = 1, y = 1, 
                           label = "No Significant Differences\nAfter Bonferroni Correction"), 
                aes(x = x, y = y, label = label)) +
      geom_text(size = 6, color = "darkred", hjust = 0.5, vjust = 0.5) +
      theme_void() +
      labs(title = "Post-hoc Analysis Results") +
      theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14))
    
    print(p)
  }
  
} else {
  cat("Post-hoc analysis not performed because Kruskal-Wallis test was not significant.\n")
}
```

# **5. HYPOTHESIS 1: COMPREHENSIVE SUMMARY**

==============================================================

## **5.0 RESEARCH QUESTION**

Do anime ratings differ systematically across different genres?

## **5.1 STATISTICAL HYPOTHESES**

-   $H₀: μ₁ = μ₂ = ... = μₖ$ (All genre means are equal)
-   $H₁: ∃ i,j: μᵢ ≠ μⱼ$ (At least one genre pair differs)

## **5.2 METHODOLOGY**

### Data Preparation

-   Initial dataset: $12017$ anime with valid genre and rating
-   Filtered dataset: $11903$ anime (minimum $30$ per genre)
-   Genres analyzed: $21$
-   Dominant genre assignment: First genre from top-15 list

### Assumption Testing

1.  **Normality (Kolmogorov-Smirnov):**
    -   Tested each genre separately $(n ≥ 5)$
    -   $14.3%$ of genres violate normality $(p < 0.05)$
    -   Large genres (Action, Adventure, Comedy) show significant deviations
2.  **Homogeneity of Variances (Levene's test):**
    -   $F(20, 11882) = 12.68$
    -   $p = < 0.001$
    -   Conclusion: Variances are not equal across genres

### Test Selection Rationale

Since both ANOVA assumptions are violated:

1\. Normality violations in $14.3%$ of genres

2\. Unequal variances (Levene's $p < 0.05$)

**Selected test: Kruskal-Wallis (non-parametric alternative to ANOVA)**

## **5.3 RESULTS**

### Primary Test: Kruskal-Wallis

-   H-statistic = $1489.51$
-   Degrees of freedom = $20$
-   p-value = $< 0.001$

### Effect Size

-   Epsilon-squared $(ε²) = 0.1237$
-   Interpretation: medium effect
-   Variance explained by genre: $12.4%$

```{r}
cat("Hypothesis 1 Results:\n")
cat("- Kruskal-Wallis test: H =", round(kruskal_result$statistic, 2), 
    ", p-value", ifelse(kruskal_result$p.value < 0.001, "< 0.001", 
                       round(kruskal_result$p.value, 4)), "\n")
cat("- Effect size (ε²):", round(epsilon_sq, 4), 
    "(", effect_interpretation, "effect)\n")
cat("- Most extreme difference: Action vs Kids (|Z| =", 
    round(abs(dunn_result$res$Z[which.max(abs(dunn_result$res$Z))]), 1), ")\n")
```

## **5.4 Statistical Decision**

**REJECT H₀** $(p < 0.001 < α = 0.05)$ There is sufficient statistical evidence that ratings differ across genres.

## **5.5 Post-hoc Analysis (Dunn's Test)**

-   Total comparisons: $210$
-   Significant pairs (p.adj $< 0.05$): $97$ (46.2%)
-   Strongest difference: **Action** vs **Kids** $(|Z| = 21.9)$

## **5.6 Descriptive Findings**

**Most common genres (by number of anime titles):**

1\. **Comedy**: 3151 titles (6.49 avg rating) \
2. **Action**: 2768 titles (6.79 avg rating) \
3. **Adventure**: 1445 titles (6.69 avg rating) \
4. **Drama**: 994 titles (6.79 avg rating) \
5. **Hentai**: 982 titles (6.2 avg rating)

**Highest-rated genres (by median rating):**

1\. **Action**: 6.88 (n = 2768) \
2. **Shounen**: 6.86 (n = 75) \
3. **Drama**: 6.81 (n = 994)

**Lowest-rated genres (by median rating):**

1\. **Music**: 5.84 (n = 447) \
2. **Kids**: 5.62 (n = 450) \
3. **Dementia**: 4.65 (n = 150)

**Rating difference:** Highest (Action) is 2.23 points higher than lowest (Music)

## **5.7 Genre Popularity Insights**

-   Top 5 genres account for 78.5% of all anime (9340/11903 titles)
-   Most common genre: **Comedy** (3151 titles, 26.5% of dataset)

## **5.8 LIMITATIONS**

1.  **Simplified genre assignment:** Multi-genre anime represented by single dominant genre
2.  **Unequal sample sizes:** Some genres have substantially more titles than others
3.  **Confounding variables:** Year, studio, budget, and episode count not controlled for
4.  **Platform bias:** Ratings from MyAnimeList may not represent all anime viewers
5.  **Cultural context:** Results may be specific to this dataset's demographic

## **5.9 PRACTICAL IMPLICATIONS**

1.  **For viewers:** Genre can serve as a useful indicator of likely enjoyment
2.  **For creators:** Understanding genre expectations may help in targeting audiences
3.  **For platforms:** Genre-based recommendations could improve user experience
4.  **For researchers:** Genre is a meaningful variable in anime quality studies

## **5.10 KEY TAKEAWAYS**

**Statistical significance:** Genre has a statistically significant effect on ratings

**Effect size:** medium effect (12.4% variance explained) \
**Practical relevance:** Meaningful for practical applications \
**Genre hierarchy:** Clear ranking of genres by median rating exists \
**Example contrast:** Action rates significantly higher than Music \
**Most common genres:** Comedy, Action, Adventure

====================================================================

# **6. Hypothesis 2: Relationship between Popularity and Rating**

====================================================================

### **6.1 Formal Hypotheses**

-   $H₀: β₁ = 0$ (no significant linear relationship between popularity and rating)
-   $H₁: β₁ ≠ 0$ (significant linear relationship exists)
-   Significance level: $α = 0.05$

**Methodology (as per Interim Report):**

1.  Logarithmic transformation of membership counts to address right-skew
2.  Simple linear regression: $ratingᵢ = β₀ + β₁·log₁₀(membersᵢ) + εᵢ$
3.  Diagnostic checks: residual normality, homoscedasticity, influential observations
4.  Model fit assessment using $R²$

## Data Preparation for Hypothesis 2

```{r}

regression_data <- anime %>%
  filter(!is.na(rating), 
         !is.na(members), 
         members > 0,
         rating > 0) %>%
  mutate(log_members = log10(members))

cat("Initial dataset size:", nrow(anime), "anime titles\n")
cat("After filtering (valid rating and members):", nrow(regression_data), "titles\n")
cat("Percentage of data used:", 
    round(nrow(regression_data)/nrow(anime)*100, 1), "%\n\n")
```

### **6.2 Linear Regression Model**

```{r}

lm_model <- lm(rating ~ log_members, data = regression_data)
summary_lm <- summary(lm_model)
```

Model: $ratingᵢ = β₀ + β₁·log₁₀(membersᵢ) + εᵢ$

**Parameter Estimates:**

```{r}
coef_table <- summary_lm$coefficients
cat("Intercept (β₀):", round(coef_table[1, 1], 4), 
    " (SE =", round(coef_table[1, 2], 4), ")\n")
cat("Slope (β₁):", round(coef_table[2, 1], 4), 
    " (SE =", round(coef_table[2, 2], 4), ")\n\n")
```

**Statistical Significance:**

```{r}
cat("t-statistic for β₁:", round(coef_table[2, 3], 4), "\n")
cat("p-value for β₁:", 
    ifelse(coef_table[2, 4] < 0.001, "< 0.001", 
           sprintf("%.6f", coef_table[2, 4])), "\n\n")

# Confidence interval
conf_int <- confint(lm_model, level = 0.95)
cat("**95% Confidence Interval for β₁:**\n")
cat(sprintf("[%.4f, %.4f]", conf_int[2, 1], conf_int[2, 2]), "\n\n")
```

**Model Fit:**

```{r}
cat("R² =", round(summary_lm$r.squared, 4), 
    sprintf("(%.1f%% of variance explained)", round(summary_lm$r.squared * 100, 1)), "\n")
cat("Adjusted R² =", round(summary_lm$adj.r.squared, 4), "\n")
cat("Residual Standard Error:", round(summary_lm$sigma, 4), "\n")
cat("F-statistic:", round(summary_lm$fstatistic[1], 2), 
    "on", round(summary_lm$fstatistic[2]), "and", 
    round(summary_lm$fstatistic[3]), "DF\n")
cat("Overall p-value:", 
    ifelse(pf(summary_lm$fstatistic[1], summary_lm$fstatistic[2], 
              summary_lm$fstatistic[3], lower.tail = FALSE) < 0.001, 
           "< 0.001", 
           sprintf("%.6f", pf(summary_lm$fstatistic[1], 
                             summary_lm$fstatistic[2], 
                             summary_lm$fstatistic[3], 
                             lower.tail = FALSE))), "\n\n")
```

## Interpretation

```{r}
beta1 <- coef(lm_model)[2]
cat("For each 1-unit increase in log₁₀(members), the rating increases by", 
    round(beta1, 3), "points on average.\n")
cat("In practical terms: A 10-fold increase in popularity (members) corresponds to", 
    round(beta1, 3), "points higher rating.\n\n")

```

## Visualizing the Relationship

```{r}
ggplot(regression_data, aes(x = log_members, y = rating)) +
  geom_point(alpha = 0.2, size = 0.8, color = "steelblue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Linear Regression: Rating vs Log10(Members)",
    subtitle = paste("R² =", round(summary_lm$r.squared, 3),
                    ", β₁ =", round(beta1, 3), 
                    ifelse(coef_table[2, 4] < 0.001, " (p < 0.001)", 
                           paste(" (p =", round(coef_table[2, 4], 4), ")"))),
    x = "log₁₀(Members)",
    y = "Rating"
  ) +
  theme_minimal()
```

### **6.3 Regression Diagnostics**

### 1. Residual Normality Assessment

```{r}
# For large datasets, use a random sample for Shapiro-Wilk test
set.seed(123)
residuals <- resid(lm_model)
sample_size <- min(5000, length(residuals))
residual_sample <- sample(residuals, sample_size)

shapiro_test <- shapiro.test(residual_sample)
cat("**Shapiro-Wilk test** (on random sample of n =", sample_size, "):\n")
cat("- Test statistic W =", round(shapiro_test$statistic, 4), "\n")
cat("- p-value =", 
    ifelse(shapiro_test$p.value < 0.001, "< 0.001", 
           sprintf("%.4f", shapiro_test$p.value)), "\n")
cat("- Interpretation:",
    ifelse(shapiro_test$p.value > 0.05, 
           "Residuals appear normally distributed (p > 0.05)",
           "Residuals deviate significantly from normality (p < 0.05)"), "\n\n")

# Q-Q plot for visual assessment
qqnorm(residuals, main = "Q-Q Plot of Regression Residuals", 
       xlab = "Theoretical Quantiles", ylab = "Sample Quantiles",
       cex = 0.5)
qqline(residuals, col = "red", lwd = 2)
grid()
```

### 2. Homoscedasticity Assessment

```{r}
# Breusch-Pagan test
if (!require("lmtest")) install.packages("lmtest")
library(lmtest)

bp_test <- bptest(lm_model)
cat("**Breusch-Pagan test for heteroscedasticity:**\n")
cat("- Test statistic BP =", round(bp_test$statistic, 4), "\n")
cat("- p-value =", 
    ifelse(bp_test$p.value < 0.001, "< 0.001", 
           sprintf("%.4f", bp_test$p.value)), "\n")
cat("- Interpretation:",
    ifelse(bp_test$p.value > 0.05, 
           "Constant variance assumption holds (p > 0.05)",
           "Heteroscedasticity detected (p < 0.05)"), "\n\n")

# Residuals vs fitted plot
plot(fitted(lm_model), residuals, 
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted Values",
     pch = 20, cex = 0.5, col = rgb(0, 0, 1, 0.3))
abline(h = 0, col = "red", lwd = 2)
grid()
```

### 3. Influential Observations Detection

```{r}

cooks_d <- cooks.distance(lm_model)
n_obs <- nrow(regression_data)
influential_threshold <- 4/n_obs
influential_points <- which(cooks_d > influential_threshold)
influential_count <- length(influential_points)

cat("**Cook's distance analysis:**\n")
cat("- Threshold (4/n) =", round(influential_threshold, 5), "\n")
cat("- Number of influential observations:", influential_count, 
    paste0("(", round(influential_count/n_obs*100, 2), "% of data)\n"))
cat("- Interpretation:",
    ifelse(influential_count == 0, 
           "No influential points detected.",
           paste(influential_count, "points may have undue influence.")), "\n\n")

# Cook's distance plot
plot(cooks_d, type = "h", 
     ylab = "Cook's Distance", xlab = "Observation Index",
     main = "Cook's Distance for Influential Points Detection")
abline(h = influential_threshold, col = "red", lwd = 2, lty = 2)
if (influential_count > 0) {
  points(influential_points, cooks_d[influential_points], 
         col = "red", pch = 19, cex = 0.7)
}
```

## Robustness Checks

### 1. Robust Regression (M-estimation)

```{r}
if (!require("MASS")) install.packages("MASS")
library(MASS)

rlm_model <- rlm(rating ~ log_members, data = regression_data)
cat("**Comparison of coefficients:**\n")
cat("- OLS estimate for β₁:", round(coef(lm_model)[2], 4), "\n")
cat("- Robust estimate for β₁:", round(coef(rlm_model)[2], 4), "\n")
cat("- Difference:", round(abs(coef(lm_model)[2] - coef(rlm_model)[2]), 4), "\n")
cat("- Interpretation:",
    ifelse(abs(coef(lm_model)[2] - coef(rlm_model)[2]) < 0.01,
           "Similar estimates suggest results are robust to outliers.",
           "Substantial difference indicates sensitivity to outliers."), "\n\n")
```

### 2. Nonlinearity Check

```{r}

poly_model <- lm(rating ~ poly(log_members, 2), data = regression_data)
poly_summary <- summary(poly_model)
cat("**Quadratic term test:**\n")
cat("- Quadratic coefficient:", round(coef(poly_summary)[3, 1], 4), "\n")
cat("- p-value for quadratic term:", 
    ifelse(coef(poly_summary)[3, 4] < 0.001, "< 0.001", 
           sprintf("%.4f", coef(poly_summary)[3, 4])), "\n")
cat("- R² comparison: Linear =", round(summary_lm$r.squared, 4), 
    ", Quadratic =", round(poly_summary$r.squared, 4), "\n")
cat("- Interpretation:",
    ifelse(coef(poly_summary)[3, 4] < 0.05,
           "Evidence of nonlinearity (quadratic term is significant).",
           "No evidence of nonlinearity (linear model is adequate)."), "\n\n")
```

## **7. Discussion and Conclusions**

**Null Hypothesis (H₀):** $β₁ = 0$ (no linear relationship)

**Alternative Hypothesis (H₁):** $β₁ ≠ 0$ (linear relationship exists)

**Significance level:** $α = 0.05$

```{r}
if (coef_table[2, 4] < 0.05) {
  cat("**DECISION:** REJECT H₀\n")
  cat("**Reason:** p-value", 
      ifelse(coef_table[2, 4] < 0.001, "< 0.001", 
             sprintf("= %.4f", coef_table[2, 4])), 
      "< 0.05\n")
  cat("**Conclusion:** There is statistically significant evidence of a linear relationship\n")
  cat("between anime popularity (log10 of members) and mean rating.\n")
  
  cat("\n**Direction of relationship:** POSITIVE (β₁ > 0)\n")
  cat("**Interpretation:** More popular anime tend to receive higher ratings on average.\n")
  cat("**Effect size:** R² =", round(summary_lm$r.squared, 4), 
      sprintf("(%.1f%% of variance in ratings explained by popularity)", 
              round(summary_lm$r.squared * 100, 1)), "\n")
} else {
  cat("**DECISION:** FAIL TO REJECT H₀\n")
  cat("**Reason:** p-value =", sprintf("%.4f", coef_table[2, 4]), "> 0.05\n")
  cat("**Conclusion:** There is insufficient statistical evidence of a linear relationship\n")
  cat("between anime popularity and mean rating.\n")
}
```

### **7.1 Summary of Findings**

-   Strong positive correlation between log(members) and rating $(r = 0.648)$

-   Linear regression confirms significant positive relationship $(β₁ = 0.6566, p < 0.001)$

-   Popular anime tend to receive higher ratings

    ```{r}
    cat("Hypothesis 2 Results:\n")
    cat("- Correlation: r =", round(cor_test$estimate, 3), 
        ", p-value", ifelse(cor_test$p.value < 0.001, "< 0.001", 
                           round(cor_test$p.value, 4)), "\n")
    cat("- Regression slope (β₁):", round(coef(lm_model)[2], 4), 
        ", p-value", ifelse(coef_table[2,4] < 0.001, "< 0.001", 
                           round(coef_table[2,4], 4)), "\n")
    cat("- R² =", round(summary_lm$r.squared, 4), 
        sprintf("(%.1f%% variance explained)", round(summary_lm$r.squared * 100, 1)), "\n")
    ```

## **7.2 Limitations and Considerations**

1.  **Log transformation assumption:** We assume $log10$ transformation adequately addresses right-skew in popularity distribution.
2.  **Linearity assumption:** Relationship modeled as linear in log-space.
3.  **Causation vs correlation:** Association does not imply causation.
4.  **Omitted variables:** Other factors (genre, year, episodes) not controlled for.
5.  **Sample representativeness:** Results specific to MyAnimeList dataset.

==============================================================

## **8. Executive Summary**

This research analyzed factors influencing anime popularity using data from 12,294 anime titles and 7.8 million user ratings. Key findings:

1.  **Genre significantly affects ratings** (Kruskal-Wallis H = 1489.51, p \< 0.001)
2.  **Action anime receive highest ratings** (median = 6.88), Music lowest (median = 5.84)
3.  **Popularity strongly correlates with ratings** (r = 0.648, p \< 0.001)
4.  **Each 10-fold increase in popularity predicts 0.66 higher rating**

These findings have implications for viewers, creators, and recommendation systems.

## **9. Practical Implications**

1.  **For viewers:** Genre can guide viewing choices

2.  **For creators:** Understanding genre-rating relationships can inform production decisions

3.  **For platforms:** Popularity metrics can help predict user satisfaction

## **10. Future Research Directions**

1.  Multivariate analysis controlling for confounders

2.  Longitudinal analysis of rating trends

3.  Cross-cultural comparisons using data from different platforms

## **11. References**

1.  Kaggle Anime Recommendations Database: <https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database>

2.  MyAnimeList: <https://myanimelist.net/>

3.  Field, A., Miles, J., & Field, Z. (2012). Discovering statistics using R. Sage publications.
