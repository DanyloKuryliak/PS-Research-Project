---
title: "Statistical Analysis of Anime Popularity Factors"
author: "Solchanyk Vasyl, Dziuba Oksana, Kuryliak Danylo"
output: html_document
---

```{r setup, include=FALSE}
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("FSA")) install.packages("FSA")
if (!require("gridExtra")) install.packages("gridExtra")
if (!require("car")) install.packages("car")
if (!require("lmtest")) install.packages("lmtest")
if (!require("MASS")) install.packages("MASS")

library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(car)
library(lmtest)
library(MASS)

library(FSA)

theme_set(theme_minimal())
```

```{r}
cat("R packages used:\n")
cat("- tidyverse: data manipulation and visualization\n")
cat("- FSA: Dunn's test for post-hoc analysis\n")
cat("- car: Levene's test for homogeneity of variances\n")
cat("- lmtest: Breusch-Pagan test for heteroscedasticity\n")
cat("- MASS: robust regression\n")
```

# **1. Introduction**

## **1.1 Research Background**

This research project analyzes factors influencing anime popularity using the publicly available **Anime Recommendations Database** from Kaggle. The dataset consists of metadata for 12,294 anime titles and approximately 7.8 million user ratings.

## **1.2 Research Objectives**

1.  Test whether anime ratings differ systematically across genres (**Hypothesis** **1**)

2.  Examine the relationship between popularity and mean ratings (**Hypothesis 2**)

## **1.3 Dataset Description**

-   **anime.csv**: Metadata for 12,294 anime titles including genre, type, episodes, rating, and members count

-   **rating.csv**: \~7.8 million user-anime interactions from 73,516 users

# **2. Data Loading and Preparation**

## **2.1 Loading Data**

We load the anime metadata and user–item rating interactions from the Kaggle Anime Database. We remove unrated entries (rating = -1) and inspect the structure of both datasets to understand variable types and available information.

```{r}
anime <- read_csv("data/anime.csv") %>%
  mutate(
    episodes = case_when(
      episodes == "Unknown" ~ NA_character_,
      TRUE ~ episodes
    ),
    episodes = as.numeric(episodes)
  )

rating <- read_csv(
  "data/rating.csv",
  col_types = cols(
    user_id  = col_integer(),
    anime_id = col_integer(),
    rating   = col_integer()
  )
)

rating <- rating |> filter(rating != -1)
```

## **2.2 Data Structure**

```{r}
anime |>
  dplyr::select(anime_id, name, genre, type, episodes, rating, members) |>
  slice(1:10) |>
  knitr::kable(caption = "Example rows from the anime dataset")

rating |>
  slice(1:10) |>
  knitr::kable(caption = "Example rows from the user–anime rating dataset")

vars <- tibble::tribble(
  ~Variable,   ~Dataset, ~Type,      ~Description,
  "anime_id",  "anime",  "integer",  "Unique identifier of an anime title",
  "name",      "anime",  "character","Title of the anime",
  "genre",     "anime",  "character","Comma-separated list of genres",
  "type",      "anime",  "character","TV, Movie, OVA, etc.",
  "episodes",  "anime",  "integer","Number of episodes",
  "rating",    "anime",  "double",   "Mean user rating (1–10)",
  "members",   "anime",  "double",   "Number of users who added the anime",
  "user_id",   "rating", "integer",  "Unique user identifier",
  "rating",    "rating", "integer",  "User's rating for this anime"
)

knitr::kable(vars, caption = "Variables used in the analysis")
```

# **3. Descriptive Analysis**

## **3.1 Dataset Statistics**

```{r}
desc_stats <- anime %>%
  summarise(
    n_titles = n(),
    n_with_ratings = sum(!is.na(rating)),
    n_with_members = sum(!is.na(members) & members > 0),
    mean_rating = mean(rating, na.rm = TRUE),
    median_rating = median(rating, na.rm = TRUE),
    sd_rating = sd(rating, na.rm = TRUE),
    min_rating = min(rating, na.rm = TRUE),
    max_rating = max(rating, na.rm = TRUE),
    mean_members = mean(members, na.rm = TRUE),
    median_members = median(members, na.rm = TRUE),
    .groups = "drop"
  )

cat("Total anime titles:", desc_stats$n_titles, "\n")
cat("Anime with ratings:", desc_stats$n_with_ratings, 
    paste0("(", round(desc_stats$n_with_ratings/desc_stats$n_titles*100, 1), "%)\n"))
cat("Anime with membership data:", desc_stats$n_with_members, "\n\n")
```

## **3.2 Dataset Statistics**

```{r}
cat("Mean rating:", round(desc_stats$mean_rating, 2), "\n")
cat("Median rating:", round(desc_stats$median_rating, 2), "\n")
cat("Standard deviation:", round(desc_stats$sd_rating, 2), "\n")
cat("Range:", round(desc_stats$min_rating, 2), "-", round(desc_stats$max_rating, 2), "\n\n")


stats_table <- tribble(
  ~Statistic, ~Rating, ~Members,
  "Mean", sprintf("%.2f", desc_stats$mean_rating), 
          sprintf("%.0f", desc_stats$mean_members),
  "Median", sprintf("%.2f", desc_stats$median_rating), 
            sprintf("%.0f", desc_stats$median_members),
  "SD", sprintf("%.2f", desc_stats$sd_rating), "N/A",
  "Min", sprintf("%.2f", desc_stats$min_rating), "1",
  "Max", sprintf("%.2f", desc_stats$max_rating), 
          sprintf("%.0f", max(anime$members, na.rm = TRUE))
)

knitr::kable(stats_table, caption = "Descriptive Statistics of Key Variables")

```

## **3.3 Distribution of Ratings**

The histogram of mean ratings shows the overall shape of the rating distribution. This helps identify whether the ratings are symmetric, skewed, tightly clustered, or widely spread.

```{r}
ggplot(anime %>% filter(!is.na(rating)), aes(x = rating)) +
  geom_histogram(bins = 35, fill = "steelblue", alpha = 0.8) +
  labs(
    title = "Distribution of Anime Mean Ratings",
    subtitle = paste("N =", sum(!is.na(anime$rating)), "anime with ratings"),
    x = "Mean rating",
    y = "Count"
  ) +
  theme_minimal()
```

## **3.4 Distribution of Popularity (Members)**

Popularity is strongly right-skewed, so we use a log scale for clarity. This confirms that a small number of anime dominate in viewership, while most titles have modest audience sizes.

```{r}
ggplot(anime %>% filter(!is.na(members), members > 0), aes(x = members)) +
  geom_histogram(bins = 50, fill = "darkgreen", alpha = 0.7) +
  scale_x_log10() +
  labs(
    title = "Popularity Distribution (log scale)",
    subtitle = paste("N =", sum(!is.na(anime$members) & anime$members > 0), "anime with membership data"),
    x = "Members (log10 scale)",
    y = "Count"
  ) +
  theme_minimal()
```

## **3.5 Relationship between Popularity and Rating**

```{r}
options(warn = -1)

ggplot(anime %>% filter(!is.na(rating), !is.na(members), members > 0), 
       aes(x = log10(members), y = rating)) +
  geom_point(alpha = 0.3, size = 1.5) +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Relationship between Popularity and Rating",
    subtitle = "Logarithmic scale for membership count",
    x = "log10(Members)",
    y = "Rating"
  ) +
  theme_minimal() +
  theme(legend.position = "none")


cor_test <- cor.test(
  log10(anime$members[!is.na(anime$rating) & !is.na(anime$members) & anime$members > 0]),
  anime$rating[!is.na(anime$rating) & !is.na(anime$members) & anime$members > 0]
)
```

## **3.6 Correlation alanisys**

```{r}
cat("Pearson correlation between log(members) and rating:\n")
cat("r =", round(cor_test$estimate, 3), "\n")
cat("95% CI: [", round(cor_test$conf.int[1], 3), ",", 
    round(cor_test$conf.int[2], 3), "]\n")
cat("p-value:", ifelse(cor_test$p.value < 0.001, "< 0.001", 
                      round(cor_test$p.value, 4)), "\n")

```

# **4. Hypothesis 1: Genre Differences in Ratings (Does the average rating differ between genres?)**

## **4.1 Formal Hypotheses**

-   **H₀:** $μ₁ = μ₂ = ... = μₖ$ (All genre means are equal)

-   **H₁:** $∃ i,j: μᵢ ≠ μⱼ$ (At least one genre pair differs)

## **4.2 Data Preparation for Genre Analysis**

We convert multi-genre strings into individual genre entries and compute the average rating per genre. Displaying only the top ten genres makes the comparison interpretable and highlights which categories tend to receive higher user ratings.

### STRATEGY: Dominant Genre Analysis

For each anime, select the MOST COMMON genre from top genres list

```{r}
anime_prepared <- anime %>%
  filter(!is.na(rating), !is.na(genre), genre != "") %>%
  mutate(
    genre_list = str_split(genre, ", "),
    genre_count = sapply(genre_list, length)
  )

genre_frequency <- anime_prepared %>%
  unnest(genre_list) %>%
  group_by(genre = genre_list) %>%
  summarise(
    frequency = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(frequency))

top_genres <- head(genre_frequency$genre, 15)

assign_dominant_genre <- function(genre_vector) {
  for (genre in genre_vector) {
    if (genre %in% top_genres) {
      return(genre)
    }
  }
  return(genre_vector[1])
}

anime_with_dominant <- anime_prepared %>%
  mutate(
    dominant_genre = sapply(genre_list, assign_dominant_genre)
  )

anime_h1_filtered <- anime_with_dominant %>%
  group_by(dominant_genre) %>%
  filter(n() >= 30) %>%
  ungroup() %>%
  mutate(main_genre = as.factor(dominant_genre)) %>%
  dplyr::select(-genre_list, -dominant_genre)

cat("Total anime for analysis:", nrow(anime_h1_filtered), "\n")
cat("Number of genres analyzed:", length(unique(anime_h1_filtered$main_genre)), "\n")
```

## **4.3 Assumption Testing**

### **4.3.1 Normality Test (Kolmogorov-Smirnov)**

#### **Kolmogorov-Smirnov Test**

**Purpose:** Tests whether a sample comes from a specified distribution (we use it to test for normality).

**Theoretical Background:** The KS test compares the empirical distribution function (EDF) of the sample with the cumulative distribution function (CDF) of the reference distribution (normal distribution in our case). The test statistic D represents the maximum vertical distance between these two functions.

-   Null hypothesis (H₀): The data follow the specified distribution

-   Test statistic: $D = \sup_{x} |F_n(x) - F(x)|$\
    where:

    -   \$F_n(x) \$ = empirical distribution function: $F_n(x) = \frac{1}{n} \sum_{i=1}^{n} I_{[-\infty, x]}(X_i)$

    -   $F(x)$ = theoretical cumulative distribution function (normal distribution in our case)

    -   $\sup$ = supremum (maximum distance)

-   The test statistic D follows the Kolmogorov distribution under H₀

-   Critical values depend on sample size and significance level (α = 0.05)

**When to use:** When we need to check the normality assumption before using parametric tests like ANOVA. Particularly useful for large sample sizes where graphical methods may be insufficient.

```{r}
safe_ks_test <- function(x) {
  if (length(x) < 5) return(NA_real_)
  
  tryCatch({
    test_result <- ks.test(x, "pnorm", mean = mean(x), sd = sd(x))
    return(test_result$p.value)
  }, error = function(e) {
    return(NA_real_)
  })
}

ks_results <- anime_h1_filtered %>%
  group_by(main_genre) %>%
  summarise(
    n = n(),
    mean_rating = mean(rating, na.rm = TRUE),
    sd_rating = sd(rating, na.rm = TRUE),
    ks_p = safe_ks_test(rating),
    .groups = "drop"
  ) %>%
  mutate(
    normality_violated = ks_p < 0.05 & !is.na(ks_p),
    ks_p_formatted = ifelse(is.na(ks_p), "NA", 
                           ifelse(ks_p < 0.001, "< 0.001", 
                                  sprintf("%.3f", ks_p)))
  )

normality_summary <- ks_results %>%
  summarise(
    total_genres = n(),
    genres_with_ks = sum(!is.na(ks_p)),
    genres_violating_normality = sum(normality_violated, na.rm = TRUE),
    percent_violating = round(genres_violating_normality / genres_with_ks * 100, 1)
  )
```

#### **4.3.1.1 Normality Assessment (Kolmogorov-Smirnov)**

```{r}
cat("Total genres analyzed:", normality_summary$total_genres, "\n")
cat("Genres with valid KS test results:", normality_summary$genres_with_ks, "\n")
cat("Genres violating normality assumption:", normality_summary$genres_violating_normality, 
    "(", normality_summary$percent_violating, "%)\n")

if (normality_summary$genres_violating_normality > 0) {
  cat("\nGenres with significant deviation from normality (p < 0.05):\n")
  violating_genres <- ks_results %>%
    filter(normality_violated) %>%
    dplyr::select(main_genre, n, mean_rating, ks_p_formatted) %>%
    arrange(desc(n))
  
  print(violating_genres)
}

ggplot(ks_results %>% filter(!is.na(ks_p)), 
       aes(x = ks_p, y = reorder(main_genre, ks_p))) +
  geom_point(aes(color = normality_violated, size = n), alpha = 0.7) +
  geom_vline(xintercept = 0.05, linetype = "dashed", color = "red", alpha = 0.5) +
  scale_x_continuous(trans = "log10", 
                     breaks = c(0.001, 0.01, 0.05, 0.1, 0.5, 1)) +
  labs(
    title = "Normality Test Results by Genre",
    subtitle = "Kolmogorov-Smirnov test p-values (log scale)",
    x = "p-value (log10 scale)",
    y = "Genre",
    color = "Violates\nnormality",
    size = "Sample size"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "blue"))
```

Using Kolmogorov–Smirnov tests on mean ratings within each main genre, we found that several large genres (e.g., Action, Adventure, Comedy) have p‑values below 0.05, indicating noticeable deviations from normality and motivating the use of a non‑parametric robustness check alongside ANOVA.

### **4.3.2 Homogeneity of Variances (Levene's Test)**

#### **Levene's Test**

**Purpose:** Tests the equality of variances across groups (homoscedasticity).

**Theoretical Background:** Levene's test is an alternative to Bartlett's test that is less sensitive to departures from normality. Instead of comparing variances directly, it transforms the data by taking absolute deviations from group centers (means or medians), then performs an ANOVA on these transformed values.

-   Null hypothesis (H₀): $\sigma_1^2 = \sigma_2^2 = \cdots = \sigma_k^2$

-   Transform data: $z_{ij} = |y_{ij} - \bar{y}_j|$ where $\bar{y}_j$ is the mean or median of group j

-   Perform ANOVA on $z_{ij}$

-   Test statistic: $W = \frac{(N-k)}{(k-1)} \cdot \frac{\sum_{j=1}^{k} n_j(\bar{z}j - \bar{z})^2}{\sum{j=1}^{k} \sum_{i=1}^{n_j} (z_{ij} - \bar{z}_j)^2}$\
    where:

    -   $N$ = total sample size

    -   $k$ = number of groups

    -   $n_j$ = sample size of group j

    -   $\bar{z}_j$ = mean of transformed values in group j

    -   $\bar{z}$ = overall mean of transformed values

-   The test statistic W follows an F-distribution with (k-1, N-k) degrees of freedom

**When to use:** To check the homogeneity of variances assumption before ANOVA. Particularly robust when data are not normally distributed.

## 

```{r}
levene_result <- leveneTest(rating ~ main_genre, data = anime_h1_filtered)

cat("Homogeneity of Variances Assessment:\n")
cat("- Test statistic (F):", round(levene_result$`F value`[1], 3), "\n")
cat("- p-value:", 
    ifelse(levene_result$`Pr(>F)`[1] < 0.001, "< 0.001", 
           sprintf("%.6f", levene_result$`Pr(>F)`[1])), "\n")

if (levene_result$`Pr(>F)`[1] < 0.05) {
  cat("- Conclusion: Variances are NOT equal across genres\n")
} else {
  cat("- Conclusion: Variances are equal across genres\n")
}
```

#### **4.3.2.1 Variances assessment (Levene's Test)**

```{r}
variance_summary <- anime_h1_filtered %>%
  group_by(main_genre) %>%
  summarise(
    variance = var(rating, na.rm = TRUE),
    sd = sd(rating, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(variance))

cat("Range of variances:", 
    round(min(variance_summary$variance), 3), "-", 
    round(max(variance_summary$variance), 3), "\n")
cat("Ratio of largest to smallest variance:", 
    round(max(variance_summary$variance) / min(variance_summary$variance), 1), 
    "\n\n")

ggplot(variance_summary, aes(x = reorder(main_genre, variance), y = variance)) +
  geom_col(aes(fill = variance), alpha = 0.8) +
  geom_text(aes(label = sprintf("%.3f", variance)), 
            hjust = -0.1, size = 3) +
  coord_flip() +
  labs(
    title = "Variance of Ratings by Genre",
    subtitle = paste("Levene's test p-value:", 
                    ifelse(levene_result$`Pr(>F)`[1] < 0.001, 
                           "< 0.001", 
                           sprintf("%.4f", levene_result$`Pr(>F)`[1]))),
    x = "Genre",
    y = "Variance"
  ) +
  theme_minimal() +
  scale_fill_viridis_c(option = "B", direction = -1)
```

## **4.4 Statistical Test Selection**

Since both normality and homogeneity of variances assumptions are violated, we select the **Kruskal-Wallis test** as our primary analysis method.

**Rationale:**

1.  $14.3%$ of genres violate normality assumption

2.  Levene's test shows unequal variances $(p < 0.001)$

3.  Kruskal-Wallis is a non-parametric test that doesn't require these assumptions

### **4.5 Primary Analysis: Kruskal-Wallis Test**

#### **Kruskal-Wallis Test**

**Purpose:** Non-parametric alternative to one-way ANOVA for comparing three or more groups.

**Theoretical Background:** The Kruskal-Wallis test ranks all observations from all groups together, then compares the sum of ranks between groups. If the null hypothesis is true (all groups have the same distribution), the average ranks should be similar across groups.

-   Null hypothesis (H₀): The distributions of all groups are identical

-   Test statistic: $H = \frac{12}{N(N+1)} \sum_{j=1}^{k} \frac{R_j^2}{n_j} - 3(N+1)$\
    where:

    -   $N$ = total number of observations

    -   $k$ = number of groups

    -   $R_j$ = sum of ranks in group j

    -   $n_j$ = number of observations in group j

-   For large samples, H approximately follows a χ² distribution with (k-1) degrees of freedom

-   For small samples, exact critical values are used

**When to use:** When data are ordinal or when assumptions of normality and homogeneity of variances are violated. Also appropriate for skewed distributions or when outliers are present.

## **4.6 Primary Analysis: Kruskal-Wallis Test**

```{r}
kruskal_result <- kruskal.test(rating ~ main_genre, data = anime_h1_filtered)
```

### **4.6.1 Kruskal-Wallis Test Results**

```{r}
cat("Kruskal-Wallis Test Results:\n")
cat("- Test statistic (H):", round(kruskal_result$statistic, 2), "\n")
cat("- Degrees of freedom:", kruskal_result$parameter, "\n")
cat("- p-value:", 
    ifelse(kruskal_result$p.value < 0.001, "< 0.001", 
           sprintf("%.6f", kruskal_result$p.value)), "\n")

# Calculate effect size (epsilon-squared)
H <- kruskal_result$statistic
k <- length(unique(anime_h1_filtered$main_genre))
N <- nrow(anime_h1_filtered)
epsilon_sq <- (H - k + 1) / (N - k)

# Function to interpret epsilon-squared
interpret_epsilon <- function(epsilon_sq) {
  if (epsilon_sq < 0.01) return("negligible")
  else if (epsilon_sq < 0.06) return("small")
  else if (epsilon_sq < 0.14) return("medium")
  else return("large")
}

effect_interpretation <- interpret_epsilon(epsilon_sq)

cat("\nEffect Size Analysis:\n")
cat("- Epsilon-squared (ε²):", round(epsilon_sq, 4), "\n")
cat("- Interpretation:", effect_interpretation, "effect\n")
cat("- Variance explained by genre:", round(epsilon_sq * 100, 1), "%\n")
```

## **4.7 Hypothesis Decision**

```{r}
alpha <- 0.05
if (kruskal_result$p.value < alpha) {
  cat("\n**Decision: REJECT H₀**\n")
  cat("There is sufficient statistical evidence that ratings differ across genres.\n")
} else {
  cat("\n**Decision: FAIL TO REJECT H₀**\n")
  cat("There is insufficient evidence that ratings differ across genres.\n")
}
```

## **4.8 Post-hoc Analysis: Dunn's Test with Bonferroni Correction**

#### **Dunn's Test with Bonferroni Correction**

**Purpose:** Post-hoc pairwise comparisons after a significant Kruskal-Wallis test.

**Theoretical Background:** Dunn's test performs pairwise comparisons using rank sums to identify which specific groups differ. The Bonferroni correction adjusts significance levels to control the family-wise error rate when conducting multiple comparisons.

-   For each pairwise comparison between groups i and j:

    -   $z_{ij} = \frac{\bar{R}_i - \bar{R}j}{\sqrt{\frac{N(N+1)}{12} - \frac{\sum{s=1}^{t} (t_s^3 - t_s)}{12(N-1)}} \cdot \sqrt{\frac{1}{n_i} + \frac{1}{n_j}}}$\
        where:

    -   $\bar{R}_i = R_i/n_i$ = average rank in group i

    -   $t_s$ = number of observations tied at rank s

    -   $t$ = number of tied ranks

-   The z-statistic follows approximately a standard normal distribution

-   **Bonferroni correction:** Adjusts α level for m comparisons: $\alpha_{adj} = \frac{\alpha}{m}$\
    where m = number of pairwise comparisons = $\frac{k(k-1)}{2}$

**When to use:** To identify which specific groups differ after obtaining a significant Kruskal-Wallis result. The Bonferroni correction is conservative and controls Type I error at the expense of reduced power.

```{r}
if (kruskal_result$p.value < 0.05) {
  cat("\n## Post-hoc Analysis (Dunn's Test with Bonferroni Correction)\n")
  cat("Since the Kruskal-Wallis test was significant, we perform pairwise\n")
  cat("comparisons to identify which specific genres differ.\n\n")
  
  dunn_result <- dunnTest(rating ~ main_genre, 
                         data = anime_h1_filtered,
                         method = "bonferroni")
  
  dunn_df <- dunn_result$res
  
  significant_comparisons <- dunn_df %>%
    filter(P.adj < 0.05) %>%
    arrange(P.adj)
  
  cat("Total pairwise comparisons:", nrow(dunn_df), "\n")
  cat("Significant comparisons (p.adj < 0.05):", nrow(significant_comparisons), "\n")
  cat("Percentage significant:", 
      round(nrow(significant_comparisons) / nrow(dunn_df) * 100, 1), "%\n\n")
  
  if (nrow(significant_comparisons) > 0) {
    cat("Top 10 most significant genre differences:\n")
    
    top_comparisons <- significant_comparisons %>%
      slice_head(n = 10) %>%
      mutate(
        Significance = case_when(
          P.adj < 0.001 ~ "***",
          P.adj < 0.01 ~ "**",
          P.adj < 0.05 ~ "*",
          TRUE ~ ""
        ),
        `Adj. p-value` = ifelse(P.adj < 0.001, "< 0.001", 
                               sprintf("%.5f", P.adj)),
        Comparison = gsub(" - ", " vs ", Comparison)
      ) %>%
      dplyr::select(Comparison, Z, `Adj. p-value`, Significance)
    
    print(top_comparisons)
    
    plot_data <- top_comparisons %>%
      mutate(
        Comparison = factor(Comparison, levels = Comparison[order(abs(Z))]),
        Direction = ifelse(Z > 0, "First > Second", "Second > First"),
        Significance_Level = factor(Significance, 
                                   levels = c("*", "**", "***"),
                                   ordered = TRUE)
      )
    
    direction_colors <- c("First > Second" = "#2E8B57", "Second > First" = "#CD5C5C")
    
    p <- ggplot(plot_data, aes(x = abs(Z), y = reorder(Comparison, abs(Z)))) +
      geom_col(aes(fill = Direction), alpha = 0.85, width = 0.7) +
      geom_text(aes(label = Significance, color = Direction), 
                x = 0.5, hjust = 0, size = 5, fontface = "bold") +
      scale_fill_manual(values = direction_colors) +
      scale_color_manual(values = direction_colors) +
      labs(
        title = "Top 10 Most Significant Genre Differences",
        subtitle = "Dunn's test with Bonferroni correction",
        x = "Absolute Z-statistic (Strength of Difference)",
        y = "Genre Comparison",
        fill = "Direction of Difference",
        color = "Direction of Difference",
        caption = "Significance: * p < 0.05, ** p < 0.01, *** p < 0.001"
      ) +
      theme_minimal(base_size = 12) +
      theme(
        plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
        plot.subtitle = element_text(hjust = 0.5, color = "gray40"),
        plot.caption = element_text(hjust = 0, color = "gray50", size = 10),
        legend.position = "bottom",
        axis.title = element_text(face = "bold"),
        panel.grid.major.x = element_line(color = "gray90"),
        panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank()
      ) +
      scale_x_continuous(expand = expansion(mult = c(0, 0.1))) +
      guides(color = "none")
    
    print(p)
    
    cat("\n## Summary of Significant Comparisons\n")

    sig_summary <- significant_comparisons %>%
      mutate(
        sig_level = case_when(
          P.adj < 0.001 ~ "p < 0.001",
          P.adj < 0.01 ~ "p < 0.01",
          P.adj < 0.05 ~ "p < 0.05"
        )
      ) %>%
      count(sig_level) %>%
      arrange(factor(sig_level, levels = c("p < 0.05", "p < 0.01", "p < 0.001")))
    
    cat("Significant comparisons by level:\n")
    print(sig_summary)

    if (nrow(significant_comparisons) > 0) {
      most_extreme <- significant_comparisons[which.max(abs(significant_comparisons$Z)), ]
      genres <- str_split(most_extreme$Comparison, " - ")[[1]]
      cat("\nMost extreme difference:\n")
      cat("- Comparison:", paste(genres[1], "vs", genres[2]), "\n")
      cat("- Z =", round(most_extreme$Z, 3), "\n")
      cat("- Adjusted p =", 
          ifelse(most_extreme$P.adj < 0.001, "< 0.001", 
                 sprintf("%.5f", most_extreme$P.adj)), "\n")
    }
    
  } else {
    cat("No significant pairwise comparisons found after Bonferroni correction.\n")

    p <- ggplot(data.frame(x = 1, y = 1, 
                           label = "No Significant Differences\nAfter Bonferroni Correction"), 
                aes(x = x, y = y, label = label)) +
      geom_text(size = 6, color = "darkred", hjust = 0.5, vjust = 0.5) +
      theme_void() +
      labs(title = "Post-hoc Analysis Results") +
      theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14))
    
    print(p)
  }
  
} else {
  cat("\nPost-hoc analysis not performed because Kruskal-Wallis test was not significant.\n")
}
```

## **4.9 Sensitivity Analysis**

```{r}
# Compare single-genre vs multi-genre anime
temp_data <- anime_h1_filtered %>%
  left_join(
    anime %>% 
      dplyr::select(anime_id, genre) %>%
      mutate(
        genre_count = str_count(genre, ", ") + 1,
        is_single_genre = genre_count == 1
      ),
    by = "anime_id"
  )

single_genre <- temp_data %>% filter(is_single_genre)
multi_genre <- temp_data %>% filter(!is_single_genre)

cat("Sensitivity Analysis - Single vs Multi-genre Anime:\n")
cat("- Single-genre anime:", nrow(single_genre), "\n")
cat("- Multi-genre anime:", nrow(multi_genre), "\n")
cat("- Mean rating difference:", 
    round(mean(multi_genre$rating, na.rm = TRUE) - mean(single_genre$rating, na.rm = TRUE), 3), "\n")

if (nrow(single_genre) > 0 && nrow(multi_genre) > 0) {
  genre_count_test <- wilcox.test(single_genre$rating, multi_genre$rating)
  cat("- Wilcoxon test p-value:", 
      ifelse(genre_count_test$p.value < 0.001, "<0.001", 
             round(genre_count_test$p.value, 4)), "\n")
}
```

## **4.10 Summary of Findings for Hypothesis 1**

1.  **Statistical Significance:** Kruskal-Wallis test shows significant differences $(H = 1489.51, p < 0.001)$

2.  **Effect Size:** Medium effect ( $ε² = 0.124, 12.4%$ variance explained)

3.  **Highest-rated Genre:** Action (median = 6.88)

4.  **Lowest-rated Genre:** Music (median = 5.84)

5.  **Most Common Genre:** Comedy (3151 titles)

# **5. Hypothesis 2: Relationship between Popularity and Rating**

## **5.1 Research Question and Hypotheses**

**Research Question:** Is there a significant linear relationship between anime popularity and mean ratings?

**Formal Hypotheses:**

-   $H₀: β₁ = 0$ (No significant linear relationship)

-   $H₁: β₁ ≠ 0$ (Significant linear relationship exists)\\

## **5.2 Data Preparation**

```{r}
regression_data <- anime %>%
  filter(!is.na(rating), 
         !is.na(members), 
         members > 0,
         rating > 0) %>%
  mutate(log_members = log10(members))

cat("Dataset for regression analysis:\n")
cat("- Initial dataset:", nrow(anime), "anime titles\n")
cat("- After filtering:", nrow(regression_data), "titles\n")
cat("- Percentage used:", round(nrow(regression_data)/nrow(anime)*100, 1), "%\n")
```

## **5.3 Correlation Analysis**

#### **Pearson Correlation Coefficient**

**Purpose:** Measures the strength and direction of linear relationship between two continuous variables.

**Theoretical Background:** The Pearson correlation coefficient measures the degree to which two variables vary together, standardized by their individual variances.

-   $r  = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i -  \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2 \sum_{i=1}^{n}(y_i -  \bar{y})^2}}$

-   Range: $-1 ≤ r ≤ 1$

    -   r = 1: perfect positive linear relationship

    -   r = -1: perfect negative linear relationship

    -   r = 0: no linear relationship

-   Test statistic: $t = r\sqrt{\frac{n-2}{1-r^2}}$ follows t-distribution with (n-2) df

-   Confidence interval: $r \pm z_{\alpha/2} \sqrt{\frac{1-r^2}{n-3}}$ (using Fisher's z-transformation)

**When to use:** To quantify linear association between two continuous, normally distributed variables.

```{r}
cor_test <- cor.test(regression_data$log_members, regression_data$rating)

cat("Pearson Correlation Analysis:\n")
cat("- Correlation coefficient (r):", round(cor_test$estimate, 3), "\n")
cat("- 95% Confidence Interval: [", 
    round(cor_test$conf.int[1], 3), ",", 
    round(cor_test$conf.int[2], 3), "]\n")
cat("- p-value:", 
    ifelse(cor_test$p.value < 0.001, "< 0.001", 
           sprintf("%.6f", cor_test$p.value)), "\n")
cat("- Interpretation:", 
    if (abs(cor_test$estimate) >= 0.7) "Strong correlation"
    else if (abs(cor_test$estimate) >= 0.3) "Moderate correlation"
    else "Weak correlation", "\n")
```

## **5.4 Linear Regression Analysis**

#### **Simple Linear Regression**

**Purpose:** Models the relationship between a dependent variable and one or more independent variables.

**Theoretical Background:** Ordinary least squares (OLS) regression finds the line that minimizes the sum of squared vertical distances between observed and predicted values.

-   Model: $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$

-   Parameter estimation (OLS):

    -   $\hat{\beta}1 = \frac{\sum{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}$

    -   $\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$

-   Standard errors:

    -   $SE(\hat{\beta}1) = \sqrt{\frac{MSE}{\sum{i=1}^{n}(x_i - \bar{x})^2}}$

    -   $MSE = \frac{SSE}{n-2} = \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{n-2}$

-   Coefficient of determination: $R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$\
    where SSR = regression sum of squares, SSE = error sum of squares, SST = total sum of squares

**When to use:** To predict or explain the relationship between variables, assuming linearity, independence, homoscedasticity, and normality of residuals.

```{r}
lm_model <- lm(rating ~ log_members, data = regression_data)
summary_lm <- summary(lm_model)

coef_table <- summary_lm$coefficients
beta1 <- coef(lm_model)[2]  # Store beta1 for visualization

cat("Linear Regression Results:\n")
cat("- Model: rating = β₀ + β₁·log₁₀(members) + ε\n")
cat("- Intercept (β₀):", round(coef(lm_model)[1], 4), 
    " (SE =", round(summary_lm$coefficients[1,2], 4), ")\n")
cat("- Slope (β₁):", round(coef(lm_model)[2], 4), 
    " (SE =", round(summary_lm$coefficients[2,2], 4), ")\n")
cat("- t-statistic for β₁:", round(summary_lm$coefficients[2,3], 4), "\n")
cat("- p-value for β₁:", 
    ifelse(summary_lm$coefficients[2,4] < 0.001, "< 0.001", 
           sprintf("%.6f", summary_lm$coefficients[2,4])), "\n")
cat("- R² =", round(summary_lm$r.squared, 4), 
    sprintf("(%.1f%% of variance explained)", round(summary_lm$r.squared*100, 1)), "\n\n")

cat("Interpretation:\n")
cat("- For each 1-unit increase in log₁₀(members), rating increases by", 
    round(coef(lm_model)[2], 3), "points\n")
cat("- A 10-fold increase in popularity corresponds to", 
    round(coef(lm_model)[2], 3), "points higher rating\n")
```

### **Visualizing the Relationship**

```{r}
ggplot(regression_data, aes(x = log_members, y = rating)) +
  geom_point(alpha = 0.2, size = 0.8, color = "steelblue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Linear Regression: Rating vs Log10(Members)",
    subtitle = paste("R² =", round(summary_lm$r.squared, 3),
                    ", β₁ =", round(beta1, 3), 
                    ifelse(coef_table[2, 4] < 0.001, " (p < 0.001)", 
                           paste(" (p =", round(coef_table[2, 4], 4), ")"))),
    x = "log₁₀(Members)",
    y = "Rating"
  ) +
  theme_minimal()
```

## **5.5 Regression Diagnostics**

### **5.5.1 Residual Normality (Shapiro-Wilk Test)**

#### **Shapiro-Wilk Test**

**Purpose:** Tests for normality of residuals in regression analysis.

**Theoretical Background:** The Shapiro-Wilk test compares the ordered sample values with the expected values from a normal distribution using a weighted linear regression. It's particularly powerful for small to moderate sample sizes.

-   Test statistic: $W = \frac{\left(\sum_{i=1}^{n} a_i x_{(i)}\right)^2}{\sum_{i=1}^{n} (x_i - \bar{x})^2}$\
    where:

    -   $x_{(i)}$ are the ordered sample values $(x₁ ≤ x₂ ≤ ... ≤ xₙ)$

    -   $a_i$ are constants generated from the means, variances and covariances of the order statistics of a sample from the normal distribution

-   W ranges from 0 to 1, with values close to 1 indicating normality

-   Small values of W lead to rejection of the normality hypothesis

-   Critical values are obtained from Shapiro-Wilk tables or computational algorithms

**When to use:** To test the normality assumption in regression analysis, particularly for sample sizes ≤ 5000.

```{r}
# For large datasets, use a random sample for Shapiro-Wilk test
set.seed(123)
residuals <- resid(lm_model)
sample_size <- min(5000, length(residuals))
residual_sample <- sample(residuals, sample_size)

shapiro_test <- shapiro.test(residual_sample)
cat("**Shapiro-Wilk test** (on random sample of n =", sample_size, "):\n")
cat("- Test statistic W =", round(shapiro_test$statistic, 4), "\n")
cat("- p-value =", 
    ifelse(shapiro_test$p.value < 0.001, "< 0.001", 
           sprintf("%.4f", shapiro_test$p.value)), "\n")
cat("- Interpretation:",
    ifelse(shapiro_test$p.value > 0.05, 
           "Residuals appear normally distributed (p > 0.05)",
           "Residuals deviate significantly from normality (p < 0.05)"), "\n\n")

# Q-Q plot for visual assessment
qqnorm(residuals, main = "Q-Q Plot of Regression Residuals", 
       xlab = "Theoretical Quantiles", ylab = "Sample Quantiles",
       cex = 0.5)
qqline(residuals, col = "red", lwd = 2)
grid()
```

### **5.5.2 Homoscedasticity (Breusch-Pagan Test)**

#### **Breusch-Pagan Test**

**Purpose:** Tests for heteroscedasticity (non-constant variance) in regression models.

**Theoretical Background:** The Breusch-Pagan test examines whether the variance of errors is dependent on the values of independent variables. It's based on regressing squared residuals on the original independent variables.

1.  Estimate the original model: $y_i = \beta_0 + \beta_1 x_i + \epsilon_i$

2.  Obtain residuals: $\hat{\epsilon}_i = y_i - \hat{y}_i$

3.  Estimate auxiliary regression: $\hat{\epsilon}_i^2 = \gamma_0 + \gamma_1 x_i + u_i$

4.  Test statistic: $LM = n \times R^2_{auxiliary}$\
    where $R^2_{auxiliary}$ is the coefficient of determination from the auxiliary regression

5.  Under H₀ (homoscedasticity), $LM ∼ χ²$ with $(p-1)$ degrees of freedom\
    where $p$ = number of parameters in the auxiliary regression

**When to use:** To test the homoscedasticity assumption in regression analysis.

```{r}
bp_test <- bptest(lm_model)

cat("\nHomoscedasticity Test (Breusch-Pagan):\n")
cat("- Test statistic (BP):", round(bp_test$statistic, 4), "\n")
cat("- p-value:", 
    ifelse(bp_test$p.value < 0.001, "< 0.001", 
           sprintf("%.6f", bp_test$p.value)), "\n")
cat("- Conclusion:", 
    ifelse(bp_test$p.value > 0.05, 
           "Constant variance assumption holds",
           "Heteroscedasticity detected"), "\n")
```

### **5.5.3 Influential Observations (Cook's Distance)**

#### **Cook's Distance**

**Purpose:** Identifies influential observations in regression analysis that disproportionately affect parameter estimates.

**Theoretical Background:** Cook's distance measures how much the regression coefficients change when a particular observation is omitted. It combines information about leverage (how unusual an observation is in X-space) and residual size.

-   For observation i: $D_i = \frac{\sum_{j=1}^{n} (\hat{y}j - \hat{y}{j(i)})^2}{p \times MSE}$\
    where:

    -   $\hat{y}_j$ = predicted value for observation j using all data

    -   $\hat{y}_{j(i)}$ = predicted value for observation j when observation i is omitted

    -   $p$ = number of regression parameters (including intercept)

    -   $MSE$ = mean squared error from the full model

-   Alternative formula: $D_i = \frac{r_i^2}{p} \times \frac{h_{ii}}{(1 - h_{ii})^2}$\
    where:

    -   $r_i$ = standardized residual for observation i

    -   $h_{ii}$ = leverage (diagonal element of hat matrix $H = X(X'X)⁻¹X')$

**Rule of thumb:** Observations with $D_i > \frac{4}{n}$ are considered influential.

**When to use:** To detect influential observations that may distort regression results. Useful for diagnosing outliers and high-leverage points.

```{r}

cooks_d <- cooks.distance(lm_model)
n_obs <- nrow(regression_data)
influential_threshold <- 4/n_obs
influential_points <- which(cooks_d > influential_threshold)
influential_count <- length(influential_points)

cat("**Cook's distance analysis:**\n")
cat("- Threshold (4/n) =", round(influential_threshold, 5), "\n")
cat("- Number of influential observations:", influential_count, 
    paste0("(", round(influential_count/n_obs*100, 2), "% of data)\n"))
cat("- Interpretation:",
    ifelse(influential_count == 0, 
           "No influential points detected.",
           paste(influential_count, "points may have undue influence.")), "\n\n")

# Cook's distance plot
plot(cooks_d, type = "h", 
     ylab = "Cook's Distance", xlab = "Observation Index",
     main = "Cook's Distance for Influential Points Detection")
abline(h = influential_threshold, col = "red", lwd = 2, lty = 2)
if (influential_count > 0) {
  points(influential_points, cooks_d[influential_points], 
         col = "red", pch = 19, cex = 0.7)
}
```

## **5.6 Robustness Checks**

### 1. Robust Regression (M-estimation)

```{r}
rlm_model <- rlm(rating ~ log_members, data = regression_data)

cat("Robustness Checks:\n")
cat("- OLS estimate for β₁:", round(coef(lm_model)[2], 4), "\n")
cat("- Robust regression estimate for β₁:", round(coef(rlm_model)[2], 4), "\n")
cat("- Difference:", round(abs(coef(lm_model)[2] - coef(rlm_model)[2]), 4), "\n")
cat("- Conclusion:", 
    ifelse(abs(coef(lm_model)[2] - coef(rlm_model)[2]) < 0.01,
           "Results are robust to outliers",
           "Results may be sensitive to outliers"), "\n")
```

## **5.7 Hypothesis Decision**

```{r}

alpha <- 0.05
if (summary_lm$coefficients[2,4] < alpha) {
  cat("\n**Decision: REJECT H₀**\n")
  cat("There is statistically significant evidence of a linear relationship\n")
  cat("between anime popularity (log10 of members) and mean rating.\n")
  cat("Direction: POSITIVE (β₁ > 0)\n")
  cat("Interpretation: More popular anime tend to receive higher ratings.\n")
} else {
  cat("\n**Decision: FAIL TO REJECT H₀**\n")
  cat("There is insufficient evidence of a linear relationship.\n")
}
```

## **5.8 Summary of Findings for Hypothesis 2**

1.  **Correlation:** Strong positive correlation $(r = 0.648, p < 0.001)$

2.  **Regression:** Significant positive relationship $(β₁ = 0.6566, p < 0.001)$

3.  **Effect Size:** $R² = 0.420$ (42.0% of variance explained)

4.  **Practical Meaning:** Each 10-fold increase in popularity predicts 0.66 points higher rating

# **6. Discussion and Conclusions**

## **6.1 Key Findings**

1.  **Genre significantly affects ratings:** Action anime receive highest ratings (median = 6.88), Music lowest (median = 5.84)

2.  **Popularity strongly correlates with ratings:** More popular anime tend to receive higher ratings

3.  **Effect sizes are meaningful:** Genre explains 12.4% of variance, popularity explains 42.0%

## **6.2 Limitations**

1.  Simplified genre assignment for multi-genre anime

2.  Unequal sample sizes across genres

3.  Potential confounding variables not controlled for

4.  Data limited to MyAnimeList platform

## **6.3 Practical Implications**

1.  **For viewers:** Genre and popularity can guide viewing choices

2.  **For creators:** Understanding these relationships can inform production decisions

3.  **For platforms:** These factors can improve recommendation systems

## **6.4 Future Research Directions**

1.  Multivariate analysis controlling for additional factors

2.  Longitudinal analysis of rating trends

3.  Cross-cultural comparisons

4.  Investigation of interaction effects between variables

# **7. References**

1.  Kaggle Anime Recommendations Database: <https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database>

2.  MyAnimeList: <https://myanimelist.net/>

3.  Field, A., Miles, J., & Field, Z. (2012). Discovering statistics using R. Sage publications.
